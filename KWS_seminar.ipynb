{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUDrGrgWqUYY"
   },
   "source": [
    "This notebook is dedicated to Keyword Spotting (KWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCTpqrCIjiO1",
    "outputId": "1f22be3e-f7d1-4c6a-e31b-bf0bb45a2ccc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "### Download file for easier downloading and dataset creation\n",
    "! wget https://gist.githubusercontent.com/Kirili4ik/6ac5c745ff8dad094e9c464c08f66f3e/raw/63daacc17f52a7d90f7f4166a3f5deef62b165db/dataset_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lhrn5O-qUYZ"
   },
   "source": [
    "### Most imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jNm4rFdfqVpW",
    "outputId": "16a0368b-0a7c-4b2a-83ae-b1bc6291b727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
      "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (1.9)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
      "Collecting torchaudio==0.9.0\n",
      "  Using cached torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "Installing collected packages: torchaudio\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
      "Successfully installed torchaudio-0.9.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install wandb\n",
    "!pip install easydict\n",
    "!pip install --no-deps torchaudio==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bbUpoArCqUYa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import wandb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import distributions\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchaudio\n",
    "from IPython import display as display_\n",
    "\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsbhUFfFqUYh"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Y54vKCg7qUYh"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "set_seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5fwUK9epqUYh"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "812GwLfqqUYf"
   },
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1DuQIyRqUYf"
   },
   "source": [
    "In this notebook we will implement a model for finding a keyword in a stream.\n",
    "\n",
    "We will implement the version with CRNN because it is easy and improves the model. \n",
    "(from https://www.dropbox.com/s/22ah2ba7dug6pzw/KWS_Attention.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaN4kVAwqUYg"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D7qgcoVECrjN"
   },
   "outputs": [],
   "source": [
    "key_word = 'sheila'   # We will use 1 key word -- 'sheila'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLPSxgf-qUYg",
    "outputId": "60faff99-5e56-43e6-9416-80e95f06134f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword is sheila device is cpu\n"
     ]
    }
   ],
   "source": [
    "#!pip install easydict\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "\n",
    "def make_config(key_word):\n",
    "    config = {\n",
    "        'key_word'      : key_word,\n",
    "        'batch_size'    : 256,\n",
    "        'learning_rate' : 3e-4,\n",
    "        'weight_decay'  : 1e-5,\n",
    "        'num_epochs'    : 35,\n",
    "        'n_mels'        : 40,         # number of mels for melspectrogram\n",
    "        'kernel_size'   : (20, 5),    # size of kernel for convolution layer in CRNN\n",
    "        'stride'        : (8, 2),     # size of stride for convolution layer in CRNN\n",
    "        'hidden_size'   : 128,        # size of hidden representation in GRU\n",
    "        'gru_num_layers': 2,          # number of GRU layers in CRNN\n",
    "        'gru_num_dirs'  : 2,          # number of directions in GRU (2 if bidirectional)\n",
    "        'num_classes'   : 2,          # number of classes (2 for \"no word\" or \"sheila is in audio\")\n",
    "        'sample_rate'   : 16000,\n",
    "        'device'        : torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    }\n",
    "\n",
    "    config = edict(config)\n",
    "    return config\n",
    "\n",
    "config = make_config(key_word)\n",
    "print('keyword is', config.key_word, 'device is', config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUxfDJw1qUYi"
   },
   "source": [
    "#### Augmentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dkmkxPWQqUYe"
   },
   "outputs": [],
   "source": [
    "class AugsCreation():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.background_noises = [\n",
    "                'speech_commands/_background_noise_/white_noise.wav',\n",
    "                'speech_commands/_background_noise_/dude_miaowing.wav',\n",
    "                'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
    "                'speech_commands/_background_noise_/exercise_bike.wav',\n",
    "                'speech_commands/_background_noise_/pink_noise.wav',\n",
    "                'speech_commands/_background_noise_/running_tap.wav'\n",
    "        ]\n",
    "\n",
    "\n",
    "    def add_rand_noise(self, audio):\n",
    "        \n",
    "        # randomly choose noise\n",
    "        noise_num = torch.randint(low=0, high=len(self.background_noises), size=(1,)).item()    \n",
    "        noise = torchaudio.load(self.background_noises[noise_num])[0].squeeze()    \n",
    "        \n",
    "        noise_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "        noise_energy = torch.norm(noise)\n",
    "        audio_energy = torch.norm(audio)\n",
    "        alpha = (audio_energy / noise_energy) * torch.pow(10, -noise_level / 20)\n",
    "\n",
    "        start = torch.randint(low=0, high=int(noise.size(0) - audio.size(0) - 1), size=(1,)).item()\n",
    "        noise_sample = noise[start : start + audio.size(0)]\n",
    "\n",
    "        audio_new = audio + alpha * noise_sample\n",
    "        audio_new.clamp_(-1, 1)\n",
    "        return audio_new\n",
    "\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
    "        augs = [\n",
    "            lambda x: x,\n",
    "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
    "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
    "            lambda x: self.add_rand_noise(x)\n",
    "        ]\n",
    "        \n",
    "        return augs[aug_num](wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doBqqRX5qUYb"
   },
   "source": [
    "#### Download, generate lables & create Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGiCUehYivKw",
    "outputId": "d5335dd9-adde-45c9-86d8-7312789dc1f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Ready!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes: \n",
      "Creating labeled dataframe:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9b5a86a2389d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabeled_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_downloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_labeled_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlabeled_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[0;32m   4968\u001b[0m             )\n\u001b[0;32m   4969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4970\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4971\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import DatasetDownloader\n",
    "\n",
    "dataset_downloader = DatasetDownloader(key_word)\n",
    "labeled_data, _ = dataset_downloader.generate_labeled_data()\n",
    "\n",
    "labeled_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDPLht5fqUYe",
    "outputId": "1e712ec5-e27c-4668-f223-28f56c10edfc"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-612c807067bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# create 2 dataframes for train/val so we can use augmentations only for train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabeled_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isedunov\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2421\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[1;32m-> 2423\u001b[1;33m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2424\u001b[0m     )\n\u001b[0;32m   2425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\isedunov\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2099\u001b[0m             \u001b[1;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2100\u001b[0m             \u001b[1;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2101\u001b[1;33m             \u001b[1;34m\"aforementioned parameters.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2102\u001b[0m         )\n\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create 2 dataframes for train/val so we can use augmentations only for train\n",
    "train_df, val_df = train_test_split(labeled_data, test_size=0.2, stratify=labeled_data['label'],  random_state=21)\n",
    "train_df, val_df = train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "from utils.dataset_utils import TrainDataset\n",
    "\n",
    "# Sample is a dict of utt, word and label\n",
    "transform_tr = AugsCreation()\n",
    "train_set = TrainDataset(df=train_df, kw=config.key_word, transform=transform_tr)\n",
    "val_set   = TrainDataset(df=val_df,   kw=config.key_word)\n",
    "\n",
    "print('all train + val samples:', len(train_set)+len(val_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vbPDqd6qUYj"
   },
   "source": [
    "#### Sampler for oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfnjRKo2qUYj"
   },
   "outputs": [],
   "source": [
    "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
    "\n",
    "def get_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UM8gLmHeqUYj"
   },
   "outputs": [],
   "source": [
    "train_sampler = get_sampler(train_set.df['label'].values)\n",
    "val_sampler   = get_sampler(val_set.df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jPaSsHYqUYj"
   },
   "outputs": [],
   "source": [
    "def batch_data(data):\n",
    "    wavs = []\n",
    "    labels = []    \n",
    "        \n",
    "    for el in data:\n",
    "        wavs.append(el['utt'])\n",
    "        labels.append(el['label'])\n",
    "\n",
    "    # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
    "    wavs = pad_sequence(wavs, batch_first=True)    \n",
    "    labels = torch.Tensor(labels).type(torch.long)\n",
    "    return wavs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8G9xPRVqUYk"
   },
   "source": [
    "###  Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wGBMcQiqUYk"
   },
   "outputs": [],
   "source": [
    "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=config.batch_size,\n",
    "                          shuffle=False, collate_fn=batch_data, \n",
    "                          sampler=train_sampler,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=config.batch_size,\n",
    "                        shuffle=False, collate_fn=batch_data, \n",
    "                        sampler=val_sampler,\n",
    "                        num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTlsn6cpqUYk"
   },
   "source": [
    "### Creating MelSpecs on GPU for speeeed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRXMt6it56fW"
   },
   "outputs": [],
   "source": [
    "class LogMelspec():\n",
    "    \n",
    "    def __init__(self, is_train, config):\n",
    "        # with augmentations\n",
    "        if is_train:\n",
    "            self.melspec = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(sample_rate=config.sample_rate,  n_mels=config.n_mels),\n",
    "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
    "            ).to(config.device)\n",
    "\n",
    "        # no augmentations\n",
    "        else:\n",
    "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "                sample_rate=config.sample_rate,\n",
    "                n_mels=config.n_mels\n",
    "            ).to(config.device)\n",
    "            \n",
    "\n",
    "    def __call__(self, batch):\n",
    "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))  # already on device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqkz4_gn8BiF"
   },
   "outputs": [],
   "source": [
    "melspec_train = LogMelspec(is_train=True, config=config)\n",
    "melspec_val = LogMelspec(is_train=False, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoAxmihY8yxr"
   },
   "source": [
    "### Quality measurment functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euwD1UyuqUYk"
   },
   "outputs": [],
   "source": [
    "# FA - true: 0, model: 1\n",
    "# FR - true: 1, model: 0\n",
    "\n",
    "def count_FA_FR(preds, labels):\n",
    "    FA = torch.sum(preds[labels == 0])\n",
    "    FR = torch.sum(labels[preds == 0])\n",
    "    \n",
    "    # torch.numel - returns total number of elements in tensor\n",
    "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHBUrkT1qUYk"
   },
   "outputs": [],
   "source": [
    "def get_au_fa_fr(probs, labels):\n",
    "    sorted_probs, _ = torch.sort(probs)\n",
    "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "        \n",
    "    FAs, FRs = [], []\n",
    "    for prob in sorted_probs:\n",
    "        preds = (probs >= prob) * 1\n",
    "        FA, FR = count_FA_FR(preds, labels)        \n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "    # plt.plot(FAs, FRs)\n",
    "    # plt.show()\n",
    "\n",
    "    # ~ area under curve using trapezoidal rule\n",
    "    return -np.trapz(FRs, x=FAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcEP5cEZqUYl"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26_QtIlXqUYl"
   },
   "outputs": [],
   "source": [
    "# Pay attention to _groups_ param\n",
    "\n",
    "def SepConv(in_size, out_size, kernel_size, stride, padding=0):\n",
    "    return nn.Sequential(\n",
    "        torch.nn.Conv1d(in_size, in_size, kernel_size[1], \n",
    "                        stride=stride[1], groups=in_size,\n",
    "                        padding=padding),\n",
    "        \n",
    "        torch.nn.Conv1d(in_size, out_size, kernel_size=1, \n",
    "                        stride=stride[0], groups=int(in_size / kernel_size[0]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIT6STF_qUYl"
   },
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CRNN, self).__init__()\n",
    "            \n",
    "        self.sepconv = SepConv(in_size=config.n_mels, out_size=config.hidden_size, \n",
    "                               kernel_size=config.kernel_size, stride=config.stride)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=config.hidden_size, hidden_size=config.hidden_size, \n",
    "                          num_layers=config.gru_num_layers, \n",
    "                          dropout=0.1, \n",
    "                          bidirectional=True if config.gru_num_dirs==2 else False)\n",
    "\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.sepconv(x)\n",
    "        \n",
    "        # (BS, hidden, seq_len) ->(seq_len, BS, hidden) \n",
    "        x = x.permute(2, 0, 1)\n",
    "        x, hidden = self.gru(x, hidden)\n",
    "        # x : (seq_len, BS, hidden * num_dirs)\n",
    "        # hidden : (num_layers * num_dirs, BS, hidden)\n",
    "                        \n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHZTwEdyqUYl"
   },
   "outputs": [],
   "source": [
    "class AttnMech(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AttnMech, self).__init__()\n",
    "        \n",
    "        lin_size = config.hidden_size * config.gru_num_dirs\n",
    "        \n",
    "        self.Wx_b = nn.Linear(lin_size, lin_size)\n",
    "        self.Vt   = nn.Linear(lin_size, 1, bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, data=None):\n",
    "        \n",
    "        # count only 1 e_t\n",
    "        if data is None:\n",
    "            x = inputs\n",
    "            x = torch.tanh(self.Wx_b(x))\n",
    "            e = self.Vt(x)\n",
    "            return e\n",
    "        \n",
    "        # recount attention for full vector e\n",
    "        e = inputs\n",
    "        data = data.transpose(0, 1)                # (BS, seq_len, hid_size*num_dirs)\n",
    "        alphas = F.softmax(e, dim=-1).unsqueeze(1)\n",
    "        c = torch.matmul(alphas, data).squeeze()   # attetntion_vector\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BkVo6qpqUYm"
   },
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self, config, CRNN_model, attn_layer):\n",
    "        super(FullModel, self).__init__()\n",
    "        \n",
    "        self.CRNN_model = CRNN_model\n",
    "        self.attn_layer = attn_layer\n",
    "        \n",
    "        # ll_in_size, ll_out_size = HIDDEN_SIZE * GRU_NUM_DIRS, NUM_CLASSES\n",
    "        # last layer\n",
    "        self.U = nn.Linear(config.hidden_size * config.gru_num_dirs, \n",
    "                           config.num_classes, bias=False)\n",
    "\n",
    "        \n",
    "    def forward(self, batch, hidden):\n",
    "        output, hidden = self.CRNN_model(batch, hidden)\n",
    "        # output : (seq_len, BS, hidden * num_dirs)\n",
    "        # hidden : (num_layers * num_dirs, BS, hidden)\n",
    "        \n",
    "        e = []\n",
    "        for seq_el in output:\n",
    "            e_t = self.attn_layer(seq_el) # (BS, 1)\n",
    "            e.append(e_t)\n",
    "        e = torch.cat(e, dim=1)           # (BS, seq_len)\n",
    "        \n",
    "        c = self.attn_layer(e, output)    # attention_vector\n",
    "        Uc = self.U(c)        \n",
    "        return Uc               # we will need to get probs, so we use return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3W-MOJLqUYm",
    "outputId": "8a216a6e-f688-401f-8dad-2fe55b9e3c60",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullModel(\n",
      "  (CRNN_model): CRNN(\n",
      "    (sepconv): Sequential(\n",
      "      (0): Conv1d(40, 40, kernel_size=(5,), stride=(2,), groups=40)\n",
      "      (1): Conv1d(40, 128, kernel_size=(1,), stride=(8,), groups=2)\n",
      "    )\n",
      "    (gru): GRU(128, 128, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  )\n",
      "  (attn_layer): AttnMech(\n",
      "    (Wx_b): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (Vt): Linear(in_features=256, out_features=1, bias=False)\n",
      "  )\n",
      "  (U): Linear(in_features=256, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "CRNN_model = CRNN(config)\n",
    "\n",
    "attn_layer = AttnMech(config)\n",
    "\n",
    "full_model = FullModel(config, CRNN_model, attn_layer)\n",
    "\n",
    "full_model = full_model.to(config.device)\n",
    "\n",
    "print(full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ev287I6SqUYn"
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(full_model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmmSFvWaqUYn"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, loader, log_melspec, gru_nl, gru_nd, hidden_size, device):\n",
    "    model.train()\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # define frist hidden with 0\n",
    "        hidden = torch.zeros(gru_nl*2, batch.size(0), hidden_size).to(device)    # (num_layers*num_dirs, BS, hidden)\n",
    "        # run model # with autocast():\n",
    "        logits = model(batch, hidden)\n",
    "        probs  = F.softmax(logits, dim=-1)            # we need probabilities so we use softmax & CE separately\n",
    "        loss   = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        \n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)                \n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
    "\n",
    "        print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIeRbn4tqUYo"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(model, loader, log_melspec, gru_nl, gru_nd, hidden_size, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_losses, accs, FAs, FRs = [], [], [], []\n",
    "    all_probs, all_labels = [], []\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)  \n",
    "\n",
    "        # define frist hidden with 0\n",
    "        hidden = torch.zeros(gru_nl*gru_nd, batch.size(0), hidden_size).to(device)    # (num_layers * num_dirs, BS, )\n",
    "        # run model   # with autocast():\n",
    "        output = model(batch, hidden)\n",
    "        probs  = F.softmax(output, dim=-1)            # we need probabilities so we use softmax & CE separately\n",
    "        loss   = F.cross_entropy(output, labels)\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        all_probs.append(probs[:, 1].cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        val_losses.append(loss.item())\n",
    "        accs.append(\n",
    "            torch.sum(argmax_probs == labels).item() /  #???\n",
    "            torch.numel(argmax_probs)\n",
    "        )\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "        \n",
    "    # area under FA/FR curve for whole loader\n",
    "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
    "    wandb.log({'mean_val_loss':np.mean(val_losses), 'mean_val_acc':np.mean(accs),\n",
    "                'mean_val_FA':np.mean(FAs), 'mean_val_FR':np.mean(FRs),\n",
    "                'au_fa_fr':au_fa_fr})\n",
    "    \n",
    "    return np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32oooz4lqUYo",
    "outputId": "107f9ef5-3fd6-41a6-e875-649b8b1d412c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  1.99it/s]\n",
      "51it [00:03, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.02it/s]\n",
      "51it [00:03, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  1.99it/s]\n",
      "51it [00:03, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.01it/s]\n",
      "51it [00:03, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.01it/s]\n",
      "51it [00:03, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.02it/s]\n",
      "51it [00:03, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.98it/s]\n",
      "51it [00:03, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  2.00it/s]\n",
      "51it [00:03, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.97it/s]\n",
      "51it [00:03, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:43,  1.96it/s]\n",
      "51it [00:03, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  1.99it/s]\n",
      "51it [00:03, 14.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.02it/s]\n",
      "51it [00:03, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.98it/s]\n",
      "51it [00:03, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.98it/s]\n",
      "51it [00:03, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:43,  1.96it/s]\n",
      "51it [00:03, 14.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.97it/s]\n",
      "51it [00:03, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  2.00it/s]\n",
      "51it [00:03, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  2.01it/s]\n",
      "51it [00:03, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.99it/s]\n",
      "51it [00:03, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:39,  2.03it/s]\n",
      "51it [00:03, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  2.01it/s]\n",
      "51it [00:03, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.98it/s]\n",
      "51it [00:03, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.99it/s]\n",
      "51it [00:03, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.02it/s]\n",
      "51it [00:03, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.01it/s]\n",
      "51it [00:03, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  1.99it/s]\n",
      "51it [00:03, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:42,  1.99it/s]\n",
      "51it [00:03, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.02it/s]\n",
      "51it [00:03, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:37,  2.09it/s]\n",
      "51it [00:03, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:39,  2.05it/s]\n",
      "51it [00:03, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.03it/s]\n",
      "51it [00:03, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:40,  2.03it/s]\n",
      "51it [00:03, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:39,  2.05it/s]\n",
      "51it [00:03, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:41,  2.01it/s]\n",
      "51it [00:03, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203it [01:37,  2.07it/s]\n",
      "51it [00:03, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 34\n"
     ]
    }
   ],
   "source": [
    "### TRAIN\n",
    "\n",
    "for n in range(config.num_epochs):\n",
    "    \n",
    "    train_epoch(full_model, opt, train_loader, melspec_train,  \n",
    "                config.gru_num_layers, config.gru_num_dirs,\n",
    "                config.hidden_size, config.device)           \n",
    "        \n",
    "    validation(full_model, val_loader, melspec_val,\n",
    "               config.gru_num_layers, config.gru_num_dirs,\n",
    "               config.hidden_size, config.device)\n",
    "\n",
    "    print('END OF EPOCH', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWaiioNzSQus"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJee_D6LqUYo"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': full_model.state_dict(),\n",
    "}, 'base_35ep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUofpIZL3WRJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KWS_seminar.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
